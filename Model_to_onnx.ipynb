{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion du modèle Pytorch en Onnx**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "from model_scn2     import ExtendedSimpleCNN2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exécution du code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation du modèle utilisé\n",
    "model = ExtendedSimpleCNN2D(3,8)\n",
    "\n",
    "# Importation des poids\n",
    "checkpoint = torch.load('./runs/class_langage-1/best_checkpoint.pth', weights_only=True)\n",
    "\n",
    "# Ajout des poids sur le modèle\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "\n",
    "# Mise en mode évaluation du modèle\n",
    "model.eval()\n",
    "\n",
    "# Exemple de donnée d'entrée : 1 image RGB (3 canneaux) de taille 128x128\n",
    "dummy_input = torch.randn(1, 3, 128, 128)\n",
    "\n",
    "# Exporter le modèle au format ONNX\n",
    "torch.onnx.export(model, dummy_input, \".\\models\\onnx\\model2.onnx\", opset_version=11,input_names=['input'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fin du code la suite ce fait sur le collab du prof car impossible sur Windows : https://colab.research.google.com/drive/1HLO2sIK_VDD7MO6CnNbWbp30GEquRWgk?usp=sharing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red; font-family: 'Arial', sans-serif; font-weight: bold; font-size: 40px;\">NON UTILISE | ANCIEN CODE EN ARCHIVE POUR GARDER DES TRACES<span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode Moi **Conversion Onnx -> Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des libraires onnx nécéssaire pour la conversion en fichier tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "\n",
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du model onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_path = '.\\onnx\\model2.onnx'\n",
    "onnx_model = onnx.load(onnx_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion du modèle onnx en tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model = prepare(onnx_model)\n",
    "\n",
    "tf_model.export_graph('./models/tensorflow_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Méthode du prof **Conversion onnx -> tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instalation des librairies nécéssaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install onnx2tf onnx-graphsurgeon onnx onnxruntime sng4onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion du modèle onnx en tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!onnx2tf -i ./02_models/onnx/model2.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion du modèle tensorflow en tensorflow-js**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TF to TF-JS\n",
    "\n",
    "!tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    --saved_model_tags=serve \\\n",
    "    /saved_model \\\n",
    "    /saved_model_tfjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test du modèle tensorflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1:\n",
      "Shape de l'entrée : (1, 3, 128, 128)\n",
      "The digit is classified as  4\n",
      "Outputs(output=array([[-142.21492, -127.56512,  -51.24095, -164.81468,  -44.7522 ,\n",
      "        -109.90031, -235.22833, -136.96535]], dtype=float32))\n",
      "Image 2:\n",
      "Shape de l'entrée : (1, 3, 128, 128)\n",
      "The digit is classified as  2\n",
      "Outputs(output=array([[-107.78237 , -138.40663 ,  -34.93393 , -154.97597 ,  -72.768364,\n",
      "        -138.90031 , -336.4368  , -168.51442 ]], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Charger l'image et la préparer\n",
    "print('Image 1:')\n",
    "img = Image.open('two.jpg').resize((128, 128)).convert('RGB')  # Convertir en RGB pour 3 canaux\n",
    "\n",
    "# Convertir l'image en un tableau numpy avec la forme correcte (1, 3, 128, 128)\n",
    "image_array = np.asarray(img, dtype=np.float32)  # (128, 128, 3)\n",
    "image_array = np.transpose(image_array, (2, 0, 1))  # Changer la forme à (3, 128, 128)\n",
    "image_array = image_array[np.newaxis, :]  # Ajouter la dimension du batch, forme (1, 3, 128, 128)\n",
    "\n",
    "# Afficher la forme de l'image pour débogage\n",
    "print(f\"Shape de l'entrée : {image_array.shape}\")\n",
    "\n",
    "# Utilisez le nom exact de l'entrée trouvé précédemment\n",
    "input_name = 'input'  # Remplacez par le nom exact trouvé\n",
    "\n",
    "# Assurez-vous que l'image est dans la forme correcte (1, 3, 128, 128)\n",
    "output = tf_model.run(image_array)  # Le modèle attend un dictionnaire\n",
    "print('The digit is classified as ', np.argmax(output))\n",
    "print(output)\n",
    "\n",
    "# Image 2\n",
    "print('Image 2:')\n",
    "img = Image.open('three.jpg').resize((128, 128)).convert('RGB')  # Convertir en RGB\n",
    "\n",
    "# Convertir l'image en un tableau numpy avec la forme correcte (1, 3, 128, 128)\n",
    "image_array = np.asarray(img, dtype=np.float32)  # (128, 128, 3)\n",
    "image_array = np.transpose(image_array, (2, 0, 1))  # Changer la forme à (3, 128, 128)\n",
    "image_array = image_array[np.newaxis, :]  # Ajouter la dimension du batch, forme (1, 3, 128, 128)\n",
    "\n",
    "# Afficher la forme de l'image pour débogage\n",
    "print(f\"Shape de l'entrée : {image_array.shape}\")\n",
    "\n",
    "# Exécuter le modèle\n",
    "output = tf_model.run(image_array)  # Remplacer 'tf_model' par votre modèle ONNX\n",
    "print('The digit is classified as ', np.argmax(output))\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projet_classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
